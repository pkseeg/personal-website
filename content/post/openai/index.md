---
title: I Spent Two Hours with OpenAI's CTO
subtitle:

# Summary for listings and search engines
summary: I'm still not sure how I feel about OpenAI's impact on the field of AI research

# Link this post with a project
projects: []

# Date published
date: "2024-06-10T00:00:00Z"

# Date updated
lastmod: "2024-06-10T00:00:00Z"

# Is this an unpublished draft?
draft: false

# Show this page in the Featured widget?
featured: false

# Featured image
# Place an image named `featured.jpg/png` in this page's folder and customize its options here.
image:
  caption: ''
  focal_point: ""
  placement: 2
  preview_only: false

authors:
- admin

tags:
- opinion
- openai
- research

categories:
- blog
---

Here are my thoughts post-visit with Mira Murati (OpenAI CTO)

* The whole thing was set up to make her and Thayer look good, so not a lot of actually insightful things happened. A lot of it was boilerplate "we're gonna make the world a better place with AI" stuff lol

* A brave soul asked her about "create rights" as it pertains to consensual scraping and use of text and images on the internet, and "biometric rights" as it pertains to use of voice and likeness (i.e. Scarjo stuff). She basically filibustered those questions, which was definitely intentional, which is the obvious strategy to me. They can't have their products without terabytes of data from non-consenting individuals that put shit on the internet pre-2019. 

* Relatedly: I honestly think that a good, newer research trend: How little data can you use? Eventually I think we'll get to a point where we need models trained on data that is explicitly consented, which will be way, way less data. Is there anything we've learned about capabilites from large models that we can translate to teeny tiny models?

* My main takeaway from her career, and from the growth of OpenAI, is that they really were the first to nail the product of LLMs. She even said this. She said "we didn't start by building GPT-3.5, we started by building the API." To me that's OpenAI's greatest contribution to the world: easy access to generative transformer-based products. I already sort of thought this, but it was interesting that she confirmed

* Here are a few funny quotes that she said
"It's not really clear how our models work"

blah blah blah "we've built something that truly understands language"

"we don't know how AI will impact jobs and we need to research this, as there is no rigorous research being done in this area right now"

"We believe in mitigating risk by providing people with tools and education (LMAO) to enable shared responsibility of AI safety" (flies in the face of their closed-book policies)